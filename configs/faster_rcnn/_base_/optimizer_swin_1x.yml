epoch: 200

LearningRate:
  base_lr: 0.0008
  schedulers:
  - !CosineDecay
    max_epochs: 200
    use_warmup: False
  - !LinearWarmup
    start_factor: 0.
    steps: 2000

OptimizerBuilder:
  optimizer:
    momentum: 0.9
    type: Momentum
  regularizer:
    factor: 0.0005
    type: L2
#OptimizerBuilder:
#  clip_grad_by_norm: 1.0
#  optimizer:
#    type: AdamW
#    weight_decay: 0.05
#    without_weight_decay_params: ['absolute_pos_embed', 'relative_position_bias_table', 'norm']
